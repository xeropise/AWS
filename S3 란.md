### Amazon S3 란?

![img](https://user-images.githubusercontent.com/50399804/133894857-485b434b-abba-48f6-8a43-c0e608e2117e.png)



- 스마트한 <u>객체 스토리지</u> 서비스

  - 다른 서비스와 연동이 쉽다.

  

- 다양한 기능을 제공한다.

  - 웹 서버 기능

  - 쿼리 기능

  - 확장 및 축소가 간단하다.

  - 다양한 관리 기능 (스토리지 클래스 분석과 리전 간 복제, 암호화 등등...)

    

- 사용하기 쉽고 견고하다는 것이 특징이다.

<br>



> 객체 스토리지?
>
> - 데이터를 객체 단위로 관리하는 형식을 말함 <br>
> - 웹 서버나 회사 내의 파일 서버와 같이 인터넷상에 데이터를 저장하는 장소를 제공해 주는 것 <br>
> - 용량 제한이 없으므로 나중을 대비해서 넉넉하게 용량을 확보할 필요 없이 최소한의 용량만으로 시작해도 좋다.



***

### S3의 특징

- 확장성

  - EC2와 마찬가지로 확장, 축소가 쉽다. 사용 목적에 맞게 다양한 스토리지 클래스가 준비되어 있고 수명주기 정책을 사용하여 자동으로 이동이 가능하다.

    

- 가용성 · 내구성

  - 99.9999999999%의 데이터 내구성을 가지고 있어, 장애나 오류, 위협에 강하다.

    

  - S3 객체는 최소 4개의 가용 영역에 자동으로 복제되어 보존되기 때문에 어느 한쪽에 장애가 발생하더라도 계속 사용할 수 있다.

    

- 신뢰성

  - 암호화 기능과 접근 관리 도구가 있어 공격으로부터 지키기 쉽다. 

    

  - 각종 규정을 준수하며 감사 기능을 갖추고 있다. 

    - PCI-DSS, HIPAA/HITECH, FedRAMP, 유럽 연합(EU) 데이터 보호 규칙 및 FISMA 등 규정 준수 프로그램 유지

    

- 다양한 관리 기능

  - 스토리지 클래스 분석, 수명 주기 정책 등을 시작으로 각종 관리 기능이 있다.

    

  - 관리 기능을 사용하면 실제 사용 환경에 맞는 스토리지 클래스를 선택하는 것이 가능하다.

    

- 스마트한 기능

  - S3 Select라는 데이터에 쿼리를 실행하는 기능과 서비스가 있다.

    

  - 그 외에 Amazon Athena, Amazon Redshift Spectrum 등의 분석 서비스와 호환되고, AWS Lambda와 연동할 수 있다.



<br>

***

### 요금 특징

- 스토리지 클래스(종류)와 리전에 따라 다르지만, 기본적인 계산식은 다음으로 계산된다.

  - '종량 과금' = '보유하고 있는 용량(데이터를 저장한 양에 따라 과금)' + '전송량(데이터를 주고 받은 전송량에 따라 과금)'

    

- 스토리지 클래스에 따라 일할(일단위로 나눔)하여 계산하는 경우와 30일 단위, 90일 단위, 180일 단위로 계산하는 경우 등 방식이 다르다.

  - 스토리지 클래스에 따라서 최소 용량 요금이 설정되어 있어, 크기보다 작은 파일인 경우도 올림하여 요금이 부과된다.

    

- S3에 대해 파일을 받거나 보낼 때 발생하는 요금인 전송량은 수신 요청(GET)이나 송신 요청(PUT)에 대해서 1GB 단위로 과금된다.



<br>

***

### 스토리지 클래스 - 다양한 종류의 스토리지

- 스토리지 클래스란?

  - 스토리지의 종류로 Standard 외에도 액세스 패턴에 따라 계층(비용이 다른 층)을 이동할 수 있는 클래스, 액세스가 빈도가 낮은 데이터를 위한 클래스 등이 있어서 사용자가 사용 목적에 맞춰서 선택이 가능하다.

    

- 버킷(객체를 저장하는 컨테이너) 단위가 아니고 객체(파일) 단위로 클래스를 선택할 수도 있다.

  

- 상황에 따라 변경할 수 있는 점이 큰 장점이며, 변경은 수동으로 해야 하지만 수명 주기 정책을 설정하며 자동으로 수행하도록 하는 것도 가능하다.



- 스토리지 클래스의 종류는 다음과 같다.

  1. Standard

     - 가장 일반적인 스토리지 클래스

       

     - 3곳 이상의 AZ(Access Zone: 가용 영역)에 데이터가 저장되어 있기 때문에 99.9%의 가용성(시스템이 계속해서 가동하는 것)을 보장한다.

       

     - 데이터를 검색할 때의 요금과 최소 용량(최소량)의 요금이 없고 일할로 계산되므로 쉽게 사용하기에 좋은 클래스이다.

       

  2. Intelligent-Tiering

     - 빈번한 액세스와 간헐적 액세스에 최적화된 두 가지 계층에 객체(파일)를 저장한다.

       

     - 어느 쪽에 저장할지는 객체별로 모니터링하여 그 결과에 따라 자동으로 이동된다.

       - 30일간 연속으로 액세스가 없는 객체는 간헐적 액세스 계층으로 이동, 액세스가 늘어나면 다시 빈번한 액세스 계층으로 이동된다.

         

     - 이 클래스에는 검색 요금이 부과되지 않는다. 액세스 계층 간 이동에 대한 요금도 부과되지 않는다.

       

     - 자주 사용되는 파일과 자주 사용도지 않는 파일이 섞여 있어서 액세스 빈도가 자주 바뀌는 경우에 비용을 줄일 수 있다.

       

     - 기본적으로 Standard와 동일하지만 최소 저장 기간에 대한 요금이 설정되어 있으므로 주의가 필요하다.

     

  3.  Infrequent Access

     - Standard 클래스에 비해 저장 요금이 낮게 설정되어 있는 대신에 액세스 요금이 조금 높게 설정되어 있다. 

       

     - 액세스 빈도가 낮고 용량이 큰 데이터에 적합하다.

       

     - 같은 Infrequent Access 중에서도 OneZone - Infrequent Access와 Standard - Infrequent Access는 저장에 사용되는 AZ의 수가 다르다.

       - OneZone의 경우 해당 지역에 물리적인 문제가 발생하면 데이터를 유실한 가능성이 있다.

         - 낮은 가격에 데이터를 보관할 수 있지만, 절대 유실하면 안 되는 데이터를 보관하기에는 맞지 않다.

           

  4. Reduced Redundancy Storage

     - 스토리지 클래스가 아닌 옵션으로 분류되지만 한 종류밖에 없기 때문에 실질적으로 스토리지 클래스의 하나라고 생각하는 것이 좋다.

       

     - Standard에 비해 이중화 수준을 낮춰서 낮은 가격으로 제공하고 있다. 저장되는 AZ가 한 군데이므로 문제가 발생할 경우에 데이터를 유실할 가능성이 있다.

       

  5. S3 Glacier / S3 Glacier Deep Archive

     - 데이터 아카이브와 장기간 백업을 고려하여 만든 스토리지 클래스이다. 다른 클래스와 마찬가지로 좋은 내구성을 가지고 있고, 가격이 낮기 때문에 대용량 데이터를 저렴한 가격으로 보관할 수 있다.

       

     - 데이터는 '볼트' 라고 하는 컨테이너에 저장된다. <u>저장된 데이터를 읽는 경우 다른 S3 버킷으로 옮겨야 하는 작업이 필요하다.</u>

       

     - 범위로 검색해서 일부 데이터만 검색할 수도 있지만, 기본적으로는 통째로 검색한다.

       

     - 검색할 경우, Glacier 상의 데이터와 검색 대상의 데이터 양쪽에 요금이 부과되므로 주의하자.



<br>

***

### S3의 사용절차 - 스토리지 서비스를 사용하기까지



#### S3 조작

![제목 없음2](https://user-images.githubusercontent.com/50399804/133894939-2c79bb2f-a678-48ae-8972-03673b914b43.png)

​	

- 버킷의 생성 및 각종 설정과 같은 기본적인 S3 조작은 관리 콘솔의 S3 대시보드에서 수행한다.

  

- 가장 기본적으로 객체(파일)의 업로드를 수행할 수 있다.

  - 일반적인 파일을 업로드하려면 매번 관리 콘솔에서 로그인해야 하기 때문에 번거롭지만, S3의 경우 API와 SDK 를 사용하여 업로드할 수 있어 편리하다.

    

  - 또한, AWS Transfer foe SFTP 가 제공되어, SFTP ([SSH](https://velog.io/@hyeseong-dev/%EB%A6%AC%EB%88%85%EC%8A%A4-ssh%EB%9E%80) 로 암호화된 파일 전송 프로토콜)로 액세스할 수 있다.



<br>

***

### S3 서비스의 기능

- 용어들에 대해 알아보자.

  

| 항목                               | 내용                                                         |
| ---------------------------------- | ------------------------------------------------------------ |
| 객체                               | S3의 엔티티 단위, 텍스트나 이미지등의 파일                   |
| 버킷                               | 객체를 저장하는 컨테이너, 모든 객체는 버킷에 저장된다.       |
| 버킷명                             | <u>S3 버킷의 명칭은 다른 AWS 사용자를 포함하여 유일한 이름</u>이어야 한다.  <br>웹 서버로 사용할 경우는 도메인명이 버킷명이 된다. |
| 객체 키                            | 객체 식별자로 모든 객체는 반드시 한 개의 키를 가진다. <br>버킷, 객체, 키, 버전을 조합하여 객체를 고유하게 식별한다. 이름이라고 생각하자. |
| 객체 메타데이터                    | 이름과 값의 세트, 객체를 업로드할 때 설정할 수 있다. <br>객체 키는 S3가 파일을 식별하기 위한 데이터이지만 메타데이터는 사람이 파일을 쉽게 관리하기 위한 데이터이다. |
| 리전                               | 버킷의 물리적인 보관 장소가 있는 지역을 말한다. (Us-East, Asia-Seoul ... 등등) |
| Amazon S3의 <br>데이터 일관성 모델 | S3는 가용성을 유지하기 위해 데이터를 자동으로 복제하여 저장하지만 쓰기 지연에 의한 데이터 불일치가 발생하면 <br>안 되기 때문에 데이터의 무결성을 보장한다. 복제가 모두 반영되기까지 다소 시간이 걸릴 수 있다. |
| 버전 관리                          | 여러 버전을 보관하는 것이다. 다른 버전은 별도의 객체로 취급하는 것이 가능하다. |
| 로그                               | 버킷 단위나 객체 단위의 로그를 기록할 수 있다. 하지만 객체 수준의 경우 유료이다. |
| 암호화                             | S3에 저장되는 데이터를 자동으로 암호화할 수 있다.            |
| 액세스 제어                        | S3 버킷에 대해 권한을 설정할 수 있다.                        |
| 웹 서비스                          | S3 버킷을 웹 사이트로 사용하는 기능이다.                     |



<br>

***

### S3 사용절차

- S3를 사용하려면 EC2와 마찬가지로 관리 콘솔에서 S3 대시보드를 열고 버킷을 생성해야 한다.

  

- S3는 매니지드 서비스이므로 기본적으로 대시보드에서 작업한다. EC2처럼 SSH로 접속하지 않는다.

  

- 또한 FTP도 지원하지 않는다. 대시보드 외에는 S3를 지원하는 전용 도구를 사용하면 접속할 수 있다.

  

- 간략하게 요약하면 다음과 같다.

  - AWS에 로그인한다.

    

  - 버킷을 만든다.

    

  - 버킷을 설정한다. 

    - 웹 서버로 사용할 경우, Static website hosting 을 설정한다.

    - 접근할 수 있는 사용자를 설정한다.

      

  - 파일을 업로드 한다.



> 객체에 [태그](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-tagging.html)를 달 수 있는데, 이 태그는 객체를 찾을 때 사용하거나 프로그램에 전달하는 설정 값으로 사용한다.



<br>

***

### S3 버킷 생성 전 검토해야 할 것

- <u>S3 버킷을 생성한 후에는 이름과 리전을 변경할 수 없다.</u>

  

- 반드시 정해야 할 것은 어떤 용도로 사용할 것인가이다.

  - 파일 서버인가, 로그저장소 인가?

    - 사용법에 맞게 도구나 SFTP를 준비한다. (파일 서버)
    - 접속 대상과 인증 방법을 고려해야 한다. (로그 저장소)

    

  

- 클라우드 서비스이기 때문에 최소 크기로 생성한 후, 나중에 크기를 변경할 수 있지만, 만약 웹 서버로 사용하려면 다른 용도에 비해 차이점이 많으므로 주의하자.

  

- 웹 서버로 사용할 경우, 버킷에 대한 공개, 도메인, 익명 접속 허가 등을 고려해야 한다.

  

- 구체적으로 정하기 어려운 경우는 테스트용 버킷을 생성해 보고 확인 한 후에 실제 사용할 스토리지를 생성하는 편이 좋다.



<br>

***

### 객체와 버킷이란?

- 버킷은 윈도우 드라이브와 같은 것이고, 객체는 파일과 같은 것이다.

  

- 버킷은 폴더가 아니므로 버킷 안에 버킷을 다시 만드는 것을 불가능하다.

  

- 버킷은 AWS 계정 하나당 100개까지 생성할 수 있다. (별도로 신청하면 1000개까지 늘릴 수 있다.)

  

- 객체도 단순한 파일이 아니라 관리를 위한 메타데이터도 포함되어 있다.

  

- 버킷 한 개에 저장할 수 있는 객체 수는 제한이 없고, 총 용량에도 제한이 없다.

  

- S3는 객체 스토리지이기 때문에 폴더나 디렉터리와 같은 개념이 없다. 객체는 버킷에 계층 구조가 아닌 병렬로 배치된다.

  

- 개념으로는 병렬이지만 사용상 편리를 위해서 관리 콘솔에 접속하면 폴더로 표시된다. 생성, 삭제, 업로드, 다운로드가 가능하다.



<br> 

### 버킷 생성과 명명 규칙

- 버킷을 생성하면 리전과 버킷명을 변경할 수 없기 때문에 신중하게 결정해야 한다.

  

- 특히 버킷명은 S3 안에서 유일한 이름이어야 한다. 다른 사용자가 쓰고 있는 버킷명은 사용할 수 없다.

  

- 리전을 변경해도 같은 버킷명으로 생성할 수 없기 때문에 생성한 버킷을 삭제하고 새롭게 생성해야 한다.

  

- 버킷에는 명명 규칙이 있다.

  - IP 주소 형식은 버킷명으로 쓸 수 없다.

    

  - 대문자 혹은 언더스코어는 버킷명으로 사용할 수 없다.

    

  - 버킷명은 처음과 마지막에 알파벳이나 숫자를 사용해야 한다.

    

  - DNS 명명 규칙에 따라야 하며, 3글자 이상 63글자 이하여야 한다.



<br>

***

### 버킷 정책과 사용자 정책: 액세스 제한 설정

- __S3 버킷에 대한 액세스 제한__

  - 제한을 설정하는 방법은 3가지이다.

    - 버킷 단위로 제한하는 버킷 정책

      - 해당 버킷에 접속할 수 있는 사용자를 지정

        

    - [IAM 사용자](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_users.html) 단위로 제한하는 사용자 정책

      - 접속 가능한 버킷을 지정

        

    - ACL(Access Control List: 액세스 제어 목록)에 의한 관리 정책

      - 자신 외의 다른 AWS 계정의 '읽기/쓰기'에 대해서 '허가' 혹은 '거부' 를 설정한 목록

    

  - 대상 사용자가 많은 경우 버킷을 지정하고, 버킷이 많은 경우 사용자를 지정하는 편이 좋다.

    

#### 액세스 제한의 대상과 내용

- 리소스, 작업, 효과, 보안 주체에 대해 설정할 수 있다. '누가 무엇을 어떤 것에 대해 가능한가 여부' 를 정할 수 있다.

  

| 항목      | 내용                                                         |
| --------- | ------------------------------------------------------------ |
| 리소스    | 제한 대상이 되는 버킷 및 객체, 아마존 리소스 이름을 사용하여 대상을 식별 |
| 작업      | 실제로 가능한 작업, GET(취득), PUT(배치), DELETE(삭제) 가 있다. 작업 키워드를 사용하여 지정한다. |
| 효과      | 설정 여부를 말한다. 허가(allow), 거부(deny)를 설정한다.      |
| 보안 주체 | 허가 혹은 거부할 사용자 및 계정, 서비스 등을 말한다.         |



<br>

***

### 웹 사이트 호스팅: 웹 사이트 공개

- S3는 단순한 스토리지 서비스가 아니 여러 기능을 제공하는데 그중 으뜸은 [웹 호스팅 기능](https://webruden.tistory.com/432)이다. S3에서 생성한 버킷을 그대로 웹 사이트로 사용할 수 있다.

  

- 버킷을 웹 사이트로 사용하려면 버킷을 생성할 때와 생성한 후에 몇 가지 설정을 해야 한다. (위의 링크 참조)

  - 정적 웹 호스팅을 활성화한다.

    

  - 공용 액세스(public access) 차단을 해제

    

  - 버킷 정책을 '모든 사용자'로 설정

    

  - 버킷명을 사용할 도메인명으로 지정

    

  - 개인 도메인을 소지한 경우, Amazon Route 53 등의 DNS 서비스를 사용하여 설정

    

- 버킷의 기본 설정은 제 3자가 접속할 수 없으므로 공용 액세스 차단과 버킷 정책의 설정을 변경하여 액세스를 허가해야 한다. 반대로 허가하게 되면 배포할 파일에 누구든지 접속할 수 있으므로 보안에 각별히 주의해야 한다.

  

- 버킷명으로 사용할 도메인을 지정해도 그 이름 그대로 도메인으로 사용할 수 있는 것이 아니라, 지정한 버킷명 + AWS 가 지정한 문자열이 URL이 된다.

  - 서울 도메인의 경우, '버킷명 + s3-website-apnortheast-2.amazonaws.com' 이 된다.

    

  - 도메인을 지정한 이름대로 사용하고 싶다면 DNS 설정을 해야 한다.



<br> 



### 다른 서비스로 구축한 웹 호스팅과의 차이

- AWS에는 웹 사이트 구축을 위한 몇 가지 서비스가 있다.

  - EC2, Amazon Lightsail, AWS Amplify 등등..

    

- 확장성은 S3 가 가장 높으므로 프로그램을 쓰지 않는다면 S3가 좋다.



| 서비스    | 서버 프로그램 실행          | 확장성 |
| --------- | --------------------------- | ------ |
| EC2       | ◎                           | △      |
| S3        | X                           | ◎      |
| Lightsail | ◎                           | △      |
| Amplify   | O (Amplify 독자적 프로그램) | O      |



<br>



> __Lightsail__
>
> - 웹 사이트에 필요한 서비스 전체를 정해진 가격으로 구축할 수 있는 서비스
>
>   
>
> - EC2의 경우, OS, 워드프레스, 고정 IP 주소, DNS를 준비해야 하지만,  Lightsail의 경우 이러한 복잡한 부분을 패키지 하나로 서비스한다.
>
>   
>
> - EC2 인스턴스와 달리 CPU나 메모리와 같은 사양, 대수를 변경할 수 있는 유연성은 없다.
>
>   
>
> - 변경해야 할 때는 스냅샷 이라고 하는 기능을 이용하여 백업하고, 변경하고 싶은 사양의 Lightsail을 새로 계약하여 백업에서 복원하는 작업을 수행한다.



<br>



> __Amplify__
>
> - 웹을 개발하기 위한 도구 전체를 제공하는 서비스로 개발자를 대상으로 한다.
>
>   
>
> - 자바스크립트로 AWS의 다양한 기능을 호출하여 시스템을 구축하고, HTML 파일과 이미지를 S3를 통하여 배포하거나 Lambda 라는 기능을 사용하여 백엔드 프로그램을 실행한다.
>
>   
>
> - 이러한 서비스를 조합하여 콘텐츠와 프로그램을 배포한다.



<br>



***

### 파일 업로드와 다운로드: 다양한 파일 업로드 방법

- __업로드와 다운로드__

  - 파일을 업로드하거나 다운로드하려면 관리 콘솔을 사용하는 방법과 CLI를 사용하는 방법이 있다.

    

  - 도구 및 프로그램에서 작업하려면 API나 SDK를 사용해야 한다.

    

  - 모든 파일 형식을 업로드할 수 있지만, 업로드할 수 잇는 파일 크기는 제한이 있다.

    - 관리 콘솔을 사용하는 경우 160GB까지 가능하다. (2021년 3월 기준), 이보다 클 경우 CLI나 SDK를 사용해야 한다.

      

- __다양한 업로드 방법__

  - API와 SDK

    - 서드 파티 도구를 사용해 파일을 업로드 할 수 있다. IAM 사용자에게 액세스 키와 보안 액세스 키를 발행하여 사용하고 싶은 도구에 설정한다.

      

  - 멀티 파트 업로드

    - 객체를 여러 개로 나누에 세트 하나로 업로드 할 수 있다.

      

    - 업로드 중에는 부분별로 표시되지만 업로드가 완료되면 객체 하나가 된다.

      

    - 업로드에 실패한 부분은 재전송되지만 일시적으로 정지하는 것도 가능하다.

      

    - 일시 저징해도 종료 기간이 없기 때문에, 그대로 두어도 업로드가 중지되는 일은 없다.

      

    - 100MB 이상의 파일은 멀티 파트 업로드를 사용할 것을 추천한다. 업로드할 때 일반적인 요청이나 업로드에 대한 요금이 발생하지만, 멀티 파트 업로드를 사용할 때는 요금이 따로 발생하지 않는다.

      

    - 관리 콘솔, CLI는 큰 파일을 업로드할 때 멀티 파트 업로드로 전환된다.

      

  - AWS Transfer for SFTP

    - SFTP를 사용하여 파일을 전송할 수 있는 서비스이다.

      - SFTP 도구가 아닌 SFTP 서버를 제공하는 서비스이다.

      

    - 서버 [엔드포인트](https://securitycream.tistory.com/7)를 설정하면 서드 파티의 SFTP 도구를 사용할 수 있다.

      

    - 초기 비용은 들지 않지만 SFTP 서버를 사용한 시간(활성화된 시간)과 데이터 전송량(업로드 및 다운로드)에 대해 과금된다.

      - 서울 리전은 시간당 0.30 US달러, 데이터 전송량은 전송된 GB당 0.04 US달러이다. (2021년 3월 기준)

        

  - AWS DataSync

    - [온프레미스](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=dktmrorl&logNo=221745088983) 스토리지 시스템과 AWS 스토리지 서비스(EC2, S3) 간에 대용량 데이터 전송을 위한 서비스이다.

      

    - 요금은 복사하는 데이터양에 대해서 발생한다.

      - 서울 리전은 1GB당 0.0.125 US달러이다. (2021년 3월 기준)

        

    - 그 외에 S3와 클라이언트를 연결하는 방법으로는 S3 버킷을 마치 온프레미스 스토리지처럼 사용할 수 있는 

      하이브리드 클라우드 스토리지 서비스(AWS Storage Gateway)가 있다.



<br>

***

### 액세스 관리 및 변조 방지: 부정한 액세스 감지

- 스토리지는 관리자가 아닌 사람이 액세스하는 경우가 많다. 

  

- 관리자는 어떤 작업이 있었는지 알지 못하므로, 이러한 스토리지 액세스를 감시하기 위한 액세스 기록을 무료로 제공한다.



<br>



### 액세스 로그란

- 서버에 어떤 요청이 있었는지를 기록하는 기능을 말한다.

  

- 로그에는 버킷 소유자, 버킷명, 요청자, 총 시간, 응답 시간, 작업, 응답 상태, 오류, 코드 등이 기록된다.

  

- S3 기능으로 액션 로그 기록을 제공하고 있지만 요금은 부과되지 않는다.

  

- 다만, 로그를 기록한 파일은 대상 버킷과 같은 리전의 버킷에 보관되므로 보관에 대한 요금은 발생한다.



<br>



### 그 외에 액세스 관리 방법

- __스토리지 클래스 분석__

  - 객체에 액세스 빈도를 분석하는 기능이다.

    - 객체는 설정된 날짜별로 어느 정도 그룹화되어 있어 각 그룹의 평균 전송 바이트 수를 감시한다.

      

    - 대상 객체를 필터링해서 감시하는 것도 가능하다.

      

    - 필터는 버킷당 최대 1,000개까지 설정할 수 있다.

    

  - 액세스 빈도가 낮은 데이터는 S3 Intelligent-Tiering으로 이동하는 판단 자료로 사용된다.

    

- __객체 잠금__

  - 객체를 보호하는 기능으로, 객체에 대한 변경을 허용하지 않기 때문에 객체 삭제, 덮어쓰기, 변조 등을 방지할 수 있다.

    

  - 유효 기간이 있는데, 법적으로 보관해야하는 경우에는 유효 기간에 관계없이 보존할 수 있다. 자금으로 보호되는 버킷은 Cross-Region Replication으로 복사할 수 없다.

    

  - 객체 잠금의 두 가지 보관 모드로 거버넌스 모드, 규정 준수 모드가 있다.

    - 거버넌스 모드

      - 특정 사용자에게만 객체 변경을 허가하는 모드

        

    - 규정 준수 모드

      - 모든 사용자가 객체를 변경할 수 없는 모드로, root 사용자도 불가능하다. 이 모드로 한 번 변경하면 모드와 기간을 변경할 수 없으므로 주의하자.

        

- S3 인벤토리

  - 버킷에 들어 있는 객체의 메타데이터의 목록을 매일 혹은 매주 생성하는 기능

    

  - CSV, ORC 등의 파일로 되어있다. Amazon Athena나 Amazon Redshift Spectrum 등의 빅데이터를 처리하는 도구와 조합하여 사용하면 편리하다.

  

<br>



***

### 버전 관리 · 수명 주기 · 복제 : 저장된 객체 관리

- 객체를 여러 버전으로 저장하는 기능으로, 버킷 단위로 설정한다.

  

- 버킷 관리 기능을 활성화하면 실수로 변경한 파일을 복원할 수 있다.

  

- 마찬가지로 실수로 삭제한 경우에도 버전 관리가 설정되어 있다면 파일을 복원할 수 있다.

  

- 버전 관리는 미사용(기본), 활성화, 버전 일시 중지 이렇게 세 가지 상태 중 하나로 설정할 수 있다.

  

- 이전 버전으로 되돌리려면 저장된 과거 버전 중 되돌리고 싶은 버전을 같은 버킷으로 복사한다.

  - 바로 이전 버전으로 되돌릴 경우는 최신 버전을 삭제해도 복원이 가능하다.



<br>



### 수명 주기 정책

- AWS를 잘 사용하는 요령 중 하나가 '수명 주기'를 고려하는 것이다.

  

- S#는 수명 주기 정책을 설정할 수 있다. 수명 주기 정책은 객체가 정기적으로 수행할 작업을 설정하는 기능으로, 설정 가능한 작업은 다음과 같다.



| 작업                           | 내용                                                         |
| ------------------------------ | ------------------------------------------------------------ |
| Transition                     | 객체를 다른 스토리지 클래스로 이동                           |
| Expiration                     | 유효 기간이 만료된 객체를 삭제, 객체가 버전 관리되고 있다면 최신 버전에만 적용 <br>또한, 버전이 여러 개 존재하고 삭제 표시가 있는 경우 삭제하지 않는다. |
| NoncurrentVersionTransition    | 현재 스토리지 클래스에서 객체의 유지 시간을 지정한다.        |
| NoncurrentVersionExpiration    | 과거 버전의 객체를 삭제하기 전에 유지할 시간을 지정한다.     |
| AbortIncompleteMultipartUpload | 멀티 파트 업로드 진행 상태를 유지할 최대 시간을 지정한다. <br>(지정 시간 내에 업로드가 안 되면 중지한다.) |
| ExpiredObjectDeleteMarker      | 만료된 객체 삭제 표시를 제거한다.                            |



<br>



### 교차 리전 복제

- 복제란 '복제본'을 생성하는 것이다.

  

- 교차 리전 복제(Cross-Region Replication)은 다른 리전의 버킷에 객체를 비동기적으로 복사하는 것이다.

  

- 복사 대상의 버킷은 원본 버킷과 소유자가 동일하지 않아도 되지만, 복제 작업을 수행하기 위해 IAM 역할(접근 권한)을 부여해야 한다.

  

- 복제에 사용할 두 버킷은 버전 관리가 활성화되어 있어야 하며, 같은 리전에 존재하는 버킷은 복제 설정을 할 수 없다.

  

- 교차 리전 복제를 사용하면 해외에도 백업해 둘 수 있기 때문에 서울에 재해가 발생하더라도 데이터를 유실하지 않고 보존할 수 있다.

  

- 한편 해외에 데이터를 보존하게 된다면 국외 빈출이 안 되는 데이터를 보존하지 않도록 주의해야 한다.

  - 특히 회사에서는 관리하는 고객 데이터의 경우에는 신중히 검토해야 한다.



<br>



***

### 데이터 분석과 연계: 저장된 데이터의 분석



- __데이터 분석과 연동__

  - S3의 객체나 객체의 내용에 대한 데이터를 분석하는 기능이 있다.

    

  - S3 Select와 Amazon Athena 는 CSV나 JSON과 같이 구조화된 텍스트 형식의 데이터를 SQL SELECT 문으로 실행하는 기능이다. 

    - 둘 다 모두 쿼리를 실행하기 위한 서버는 필요하지 않는다.

      

  - Amazon redshift Spectrum도 비슷한 기능을 갖고 있지만 대용량 데이터를 처리하기 떄문에 Reshift cluster가 필요하다.

    

- __데이터 분석 서비스__

  - 데이터 분석 서비스와 연동할 수 있도록 Amazon S3가 구성되어 있기 때문에 로그나 Iot 기기에서 수집한 데이터를 나중에 분석하려고 저장하는 경우도 있다.

    

  - 특히 S3 Select와 Amazon Athena 는 S3 버킷에 저장한 데이터를 분석하는 서비스이다. Amazon Redshift Spectrum은 S3 버킷 외의 다른 저장소의 데이터도 분석할 수 있다.

    

- __S3 Select__

  - CSV 파일이나 JSON 외에도 로그에 사용되는 Apache Parquet 형식도 지원한다.

    

  - 집계는 관리 콘솔에서 SQL 문을 입력하여 간단히 실행할 수 있다. CLI나 SDK를 지원하며 복잡한 집계일 경우 프로그램을 만들어 실행할 수도 있다.

    

- __Amazon Athena와 Amazon Redshift Spectrum__

  - Select에 비해 더 복잡하게 계산하고자하면 선택, S3에 저장된 파일 여러 개를 대상으로 분석할 수 있다.

    

  - Athena는 집계나 검색 방법을 저장할 수 있으므로, 이를 사용하면 반복해서 같은 작업을 할 때 편리하다.

    

  - Redshift Spectrum은 뛰어난 분석 기능을 가진 데이터 쉐어하우스로, 집계, 검색뿐 아니라 다양한 기준으로 데이터를 분석하거나 예측할 수 있다.

    

  - Amazon Redshift Spectrum는 S3 Select와 달리 어떤 대상에 대해 어떤 검색을 할지 사전에 구성해야 한다.

    

  - Amazon Athena와 가장 큰 차이점은 분석을 위한 서버의 존재 여부이다.

    

  - Athena는 매번 필요에 따라 분석용 서버를 자동으로 생성하여 실행하기 떄문에 실행하는 순간만 비용이 발생한다.

    

  - 반면 Redshift Spectrum은 미리 분석용 서버를 시작하고 이 서버를 사용하여 분석한다.

    - 처리 능력에 맞춰 저비용 서버에서 고성능 서버까지 선택할 수 있으며 데이터를 분산 처리할 수도 있다.

      

  - 대용량의 복잡한 데이터를 빠른 속도로 처리해야 할 경우 Reshift Spectrum을 사용하는 것이 좋다.
